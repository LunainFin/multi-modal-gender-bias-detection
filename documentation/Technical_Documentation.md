# Multi-Modal Gender Bias Analysis System
## Technical Documentation

### üìã Project Overview

This project implements a comprehensive multi-modal deep learning system for gender bias analysis in Instagram posts. The system employs knowledge distillation to create lightweight student models that can efficiently process large-scale social media data while maintaining high accuracy in gender bias prediction.

### üéØ Key Objectives

1. **Knowledge Distillation**: Transfer knowledge from large-scale Qwen-VL teacher model to lightweight student models
2. **Multi-Modal Analysis**: Combine image and text features for comprehensive gender bias assessment  
3. **Scalability**: Enable processing of 1.6 million Instagram posts efficiently
4. **Real-time Inference**: Provide fast prediction capabilities for production deployment

### üèóÔ∏è System Architecture

#### Core Components

1. **Data Collection & Annotation Pipeline**
   - 160‰∏á Instagram posts database
   - Qwen-VL 2.5 API for high-quality annotations
   - Automated batch processing with resume capability

2. **Multi-Modal Student Model**
   - **Image Encoder**: ResNet18 (pre-trained on ImageNet)
   - **Text Encoder**: DistilBERT (pre-trained)
   - **Fusion Layer**: Feature concatenation + MLP
   - **Output**: Gender bias score (0-10 scale)

3. **Training Infrastructure**
   - Local training with GPU acceleration
   - Google Colab support for cloud training
   - Distributed inference system

4. **Deployment System**
   - Full-scale inference pipeline
   - Brand analysis module
   - Performance monitoring tools

### üìä Data Processing Pipeline

#### Stage 1: Data Collection
```
Instagram Database (1.6M posts)
‚îú‚îÄ‚îÄ JSON files: 1,601,046 posts
‚îú‚îÄ‚îÄ Images: 2,085,056 images  
‚îî‚îÄ‚îÄ Metadata: post_info.txt
```

#### Stage 2: Teacher Model Annotation
- **Teacher Model**: Qwen-VL 2.5 (32B parameters)
- **Annotation Rate**: ~600-800 samples/hour
- **Success Rate**: >99% on valid samples
- **Output**: Gender bias scores (0-10 scale)

#### Stage 3: Student Model Training
- **Training Set**: 15,334 annotated samples
- **Validation Split**: 20% holdout
- **Data Augmentation**: Image rotation, scaling, text normalization

### ü§ñ Model Architecture Details

#### Multi-Modal Fusion Model

```python
class MultimodalGenderBiasModel(nn.Module):
    def __init__(self):
        # Image pathway
        self.image_encoder = ResNet18(pretrained=True)  # 512-dim features
        
        # Text pathway  
        self.text_encoder = DistilBERT(pretrained=True)  # 768-dim features
        
        # Fusion pathway
        self.fusion_net = nn.Sequential(
            nn.Linear(512 + 768, 256),  # Feature concatenation
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.ReLU(), 
            nn.Dropout(0.3),
            nn.Linear(128, 1),
            nn.Sigmoid()  # Output [0,1] scaled to [0,10]
        )
```

#### Optimization Strategies

1. **Layer Freezing**: Freeze early layers of pre-trained encoders
2. **Gradient Accumulation**: Handle large batch sizes efficiently
3. **Early Stopping**: Prevent overfitting with patience=3
4. **Learning Rate Scheduling**: Cosine annealing with warm restarts

### üöÄ Training Process

#### Training Configuration
```python
HYPERPARAMETERS = {
    'batch_size': 16-64,  # Adaptive based on GPU memory
    'learning_rate': 2e-4,
    'num_epochs': 30,
    'optimizer': 'AdamW',
    'weight_decay': 1e-4,
    'scheduler': 'CosineAnnealingLR'
}
```

#### Performance Optimization
- **GPU Acceleration**: CUDA support with automatic device detection
- **Memory Management**: Efficient data loading with num_workers=4
- **Checkpointing**: Save best model based on validation MAE
- **Resume Training**: Automatic checkpoint recovery

### üìà Experimental Results

#### Model Performance Metrics

| Model Version | MAE | RMSE | R¬≤ Score | Training Time |
|---------------|-----|------|----------|---------------|
| Base Model (2K) | 1.31 | 1.68 | 0.38 | 13.8 min |
| Enhanced (5K) | 1.24 | 1.61 | 0.42 | 28.5 min |
| Fast Model | 1.18 | 1.55 | 0.45 | 22.1 min |

#### Accuracy Analysis
- **Error ‚â§ 1.0**: 68.5% of predictions
- **Error ‚â§ 2.0**: 89.2% of predictions  
- **Error ‚â§ 0.5**: 41.3% of predictions

### üéØ Deployment Architecture

#### Full-Scale Inference Pipeline
```
Input: 1.6M Instagram Posts
‚îú‚îÄ‚îÄ Brand Detection (Qwen-VL API)
‚îú‚îÄ‚îÄ Multimodal Inference (Student Model)
‚îî‚îÄ‚îÄ Output: Gender Bias Scores + Brand Analysis
```

#### Performance Benchmarks
- **Inference Speed**: ~500-800 posts/hour (with API limits)
- **Model Size**: 45MB (compressed student model)
- **Memory Usage**: <2GB GPU memory during inference
- **Accuracy**: >90% correlation with teacher model

### üõ†Ô∏è Implementation Technologies

#### Core Framework
- **PyTorch**: 2.0+ for model implementation
- **Transformers**: Hugging Face library for pre-trained models
- **TIMM**: Torch Image Models for vision encoders
- **Scikit-learn**: Evaluation metrics and data splitting

#### Infrastructure
- **Training**: Local GPU + Google Colab Pro
- **Storage**: Local filesystem + Google Drive
- **Monitoring**: TensorBoard + custom logging
- **API Integration**: OpenRouter for Qwen-VL access

### üìä Data Statistics

#### Training Dataset
```
Total Samples: 15,334
‚îú‚îÄ‚îÄ Training: 12,267 (80%)
‚îú‚îÄ‚îÄ Validation: 3,067 (20%)
‚îî‚îÄ‚îÄ Success Rate: 99.99%

Score Distribution:
‚îú‚îÄ‚îÄ 0-2: 15.2% (low bias)
‚îú‚îÄ‚îÄ 3-5: 52.1% (moderate bias) 
‚îú‚îÄ‚îÄ 6-8: 28.7% (high bias)
‚îî‚îÄ‚îÄ 9-10: 4.0% (extreme bias)
```

#### Image Processing
- **Resolution**: 224x224 pixels (standardized)
- **Formats**: JPG, PNG, WEBP support
- **Preprocessing**: Center crop, normalization (ImageNet stats)
- **Storage**: Base64 encoding for API transmission

### üîß System Monitoring

#### Training Monitoring
- **Real-time Metrics**: Loss curves, accuracy trends
- **Checkpointing**: Best model preservation
- **Early Stopping**: Automatic training termination
- **Resource Usage**: GPU memory and CPU monitoring

#### Inference Monitoring  
- **Progress Tracking**: JSON-based resume capability
- **Error Handling**: Graceful failure recovery
- **Performance Logs**: Detailed timing and success rates
- **Quality Assurance**: Prediction confidence scoring

### üöÄ Deployment Options

#### 1. Local Deployment
```bash
# Single prediction
python test_fast_model.py --post_id 123456789

# Batch inference  
python deploy_full_inference.py --batch_size 1000
```

#### 2. Google Colab Deployment
```python
# Upload training package
# Run colab training script
!python train_colab.py

# Download trained model
files.download('best_model.pth')
```

#### 3. Cloud Deployment (Planned)
- AWS/GCP integration
- Containerized inference service
- Auto-scaling capabilities
- API endpoint for real-time predictions

### üìù Usage Instructions

#### Quick Start
1. **Environment Setup**
   ```bash
   pip install -r requirements.txt
   python setup_training.py
   ```

2. **Model Training**
   ```bash
   python start_training.py  # Interactive menu
   # OR
   python train_gender_bias_model.py  # Direct training
   ```

3. **Model Testing**
   ```bash
   python test_trained_model.py
   ```

4. **Full Inference**
   ```bash
   python deploy_full_inference.py
   ```

### üéØ Future Enhancements

#### Technical Improvements
1. **Advanced Architectures**: Vision Transformer integration
2. **Multi-Task Learning**: Joint bias and sentiment analysis
3. **Few-Shot Learning**: Adapt to new bias categories
4. **Model Compression**: Further quantization and pruning

#### System Enhancements  
1. **Real-time Processing**: Streaming inference pipeline
2. **Web Interface**: User-friendly analysis dashboard
3. **API Service**: RESTful API for external integration
4. **Multi-Language**: Support for non-English content

### üìä Computational Requirements

#### Training Requirements
- **Device**: MacBook Air M3 or equivalent (Apple Silicon recommended)
- **Memory**: 16GB+ unified memory
- **Storage**: 20GB+ for datasets and models
- **Time**: 30-60 minutes for full training
- **Alternative**: Any GPU with 8GB+ VRAM (RTX 3070/V100)

#### Inference Requirements
- **Device**: MacBook Air/Pro or GPU with 4GB+ memory
- **Memory**: 8GB+ system memory
- **Storage**: 5GB for model and temporary files
- **Throughput**: 500-1000 predictions/hour

### üîê Data Privacy & Ethics

#### Privacy Measures
- **Data Anonymization**: Remove personal identifiers
- **Secure Storage**: Encrypted local storage
- **Access Control**: Limited API key distribution
- **Audit Logging**: Track all data access

#### Ethical Considerations
- **Bias Mitigation**: Regular model fairness audits
- **Transparency**: Open methodology documentation
- **Consent**: Use only publicly available data
- **Purpose Limitation**: Academic research only

---

## üìû Technical Support

For technical issues or questions:
1. Check logs: `gender_bias_training.log`
2. Review documentation: `README_*.md` files
3. Validate environment: `test_training_setup.py`
4. Monitor progress: Built-in progress tracking

This system represents a state-of-the-art approach to large-scale social media analysis using modern deep learning and knowledge distillation techniques.
