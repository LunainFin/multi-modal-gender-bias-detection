#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šæ¨¡æ€å“ç‰Œæ¨ç†ç³»ç»Ÿ
å¯¹ç­›é€‰å‡ºçš„å“ç‰Œå¸–å­è¿›è¡ŒçœŸæ­£çš„å¤šæ¨¡æ€æ¨ç†ï¼ˆå›¾ç‰‡+æ–‡æœ¬ï¼‰
"""

import pandas as pd
import json
import os
import torch
import numpy as np
import logging
from datetime import datetime
from tqdm import tqdm
from PIL import Image
import sys
import ast

# å¯¼å…¥æ¨¡å‹
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from train_fast_local import LightweightGenderBiasModel

# è®¾ç½®ç¯å¢ƒå˜é‡é¿å…å†²çª
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# æ£€æµ‹æ˜¯å¦åœ¨åå°è¿è¡Œ
def is_running_in_background():
    """æ£€æµ‹æ˜¯å¦åœ¨åå°è¿è¡Œ"""
    try:
        return not sys.stdout.isatty() or not sys.stdin.isatty()
    except:
        return True

DISABLE_TQDM = is_running_in_background()

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('multimodal_inference.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class MultimodalBrandInference:
    def __init__(self):
        """åˆå§‹åŒ–å¤šæ¨¡æ€å“ç‰Œæ¨ç†ç³»ç»Ÿ"""
        self.brand_results_file = '/Users/huangxinyue/Multi model distillation/brand_analysis_results/brand_analysis_final.csv'
        self.database_path = '/Users/huangxinyue/Downloads/Influencer brand database'
        self.post_info_file = os.path.join(self.database_path, 'post_info.txt')
        self.json_dir = os.path.join(self.database_path, 'json')
        self.model_path = '/Users/huangxinyue/Multi model distillation/fast_models_5k/fast_best_model.pth'
        
        # è¾“å‡ºå’Œè¿›åº¦æ–‡ä»¶
        self.output_dir = '/Users/huangxinyue/Multi model distillation/multimodal_results'
        self.progress_file = os.path.join(self.output_dir, 'multimodal_progress.json')
        self.final_results_file = os.path.join(self.output_dir, 'multimodal_brand_analysis.csv')
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.output_dir, exist_ok=True)
        
        # æ¨¡å‹ç›¸å…³
        self.model = None
        self.tokenizer = None
        self.transform = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # æ•°æ®æ˜ å°„
        self.json_to_images = {}  # JSONæ–‡ä»¶å -> å›¾ç‰‡IDåˆ—è¡¨
        
        logger.info(f"ğŸš€ å¤šæ¨¡æ€å“ç‰Œæ¨ç†ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        logger.info(f"ğŸ“Š ä½¿ç”¨è®¾å¤‡: {self.device}")
    
    def load_progress(self):
        """åŠ è½½è¿›åº¦"""
        if os.path.exists(self.progress_file):
            try:
                with open(self.progress_file, 'r') as f:
                    progress = json.load(f)
                logger.info(f"ğŸ“ˆ ç»§ç»­æ¨ç†ï¼Œå·²å¤„ç† {progress.get('processed', 0)} ä¸ªå¸–å­")
                return progress
            except Exception as e:
                logger.warning(f"è¯»å–è¿›åº¦å¤±è´¥ï¼Œä»å¤´å¼€å§‹: {e}")
        
        return {'processed': 0, 'results': []}
    
    def save_progress(self, progress):
        """ä¿å­˜è¿›åº¦"""
        try:
            progress['timestamp'] = datetime.now().isoformat()
            with open(self.progress_file, 'w') as f:
                json.dump(progress, f, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜è¿›åº¦å¤±è´¥: {e}")
    
    def load_post_info_mapping(self):
        """åŠ è½½post_info.txtä¸­JSON->å›¾ç‰‡çš„æ˜ å°„"""
        logger.info("ğŸ“š åŠ è½½post_infoæ˜ å°„...")
        
        try:
            with open(self.post_info_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f):
                    try:
                        parts = line.strip().split('\t')
                        if len(parts) >= 5:
                            # æ ¼å¼: ç´¢å¼•å· ç”¨æˆ·å ç±»å‹ JSONæ–‡ä»¶å å›¾ç‰‡IDåˆ—è¡¨
                            json_filename = parts[3]
                            image_list_str = parts[4]
                            
                            # è§£æå›¾ç‰‡IDåˆ—è¡¨
                            try:
                                image_ids = ast.literal_eval(image_list_str)
                                if isinstance(image_ids, list):
                                    # å»æ‰.jpgåç¼€ï¼Œä¿ç•™ID
                                    image_ids = [img.replace('.jpg', '') for img in image_ids]
                                    self.json_to_images[json_filename] = image_ids
                            except:
                                continue
                                
                    except Exception as e:
                        continue
                    
                    # æ¯50ä¸‡è¡Œæ˜¾ç¤ºè¿›åº¦
                    if (line_num + 1) % 500000 == 0:
                        logger.info(f"  å·²å¤„ç† {line_num + 1:,} è¡Œï¼Œæ‰¾åˆ° {len(self.json_to_images):,} ä¸ªæ˜ å°„")
            
            logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(self.json_to_images):,} ä¸ªJSON->å›¾ç‰‡æ˜ å°„")
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½post_infoå¤±è´¥: {e}")
            raise
    
    def load_inference_model(self):
        """åŠ è½½æ¨ç†æ¨¡å‹"""
        logger.info("ğŸš€ åŠ è½½5Kæœ€ä½³å¤šæ¨¡æ€æ¨¡å‹...")
        
        # åŠ è½½æ¨¡å‹
        self.model = LightweightGenderBiasModel()
        checkpoint = torch.load(self.model_path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.to(self.device)
        self.model.eval()
        
        # åŠ è½½tokenizer
        from transformers import DistilBertTokenizer
        self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')
        
        # å›¾åƒé¢„å¤„ç†
        from torchvision import transforms
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        logger.info("âœ… å¤šæ¨¡æ€æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def find_image_paths(self, image_ids):
        """æŸ¥æ‰¾å›¾ç‰‡æ–‡ä»¶è·¯å¾„"""
        image_paths = []
        for image_id in image_ids:
            # åœ¨å„ä¸ªimg_resizedç›®å½•ä¸­æŸ¥æ‰¾
            for i in range(1, 17):
                dir_path = os.path.join(self.database_path, f'img_resized_{i}')
                image_path = os.path.join(dir_path, f'{image_id}.jpg')
                if os.path.exists(image_path):
                    image_paths.append(image_path)
                    break
        return image_paths
    
    def load_images(self, image_paths):
        """åŠ è½½å’Œé¢„å¤„ç†å›¾ç‰‡"""
        images = []
        for image_path in image_paths[:3]:  # æœ€å¤šå¤„ç†3å¼ å›¾ç‰‡
            try:
                image = Image.open(image_path).convert('RGB')
                image_tensor = self.transform(image)
                images.append(image_tensor)
            except Exception as e:
                logger.warning(f"å›¾ç‰‡åŠ è½½å¤±è´¥ {image_path}: {e}")
                continue
        
        if not images:
            # å¦‚æœæ²¡æœ‰å›¾ç‰‡ï¼Œè¿”å›é»‘è‰²å›¾ç‰‡
            return torch.zeros(1, 3, 224, 224)
        elif len(images) == 1:
            return images[0].unsqueeze(0)
        else:
            # å¤šå¼ å›¾ç‰‡å–å¹³å‡
            return torch.stack(images).mean(dim=0).unsqueeze(0)
    
    def multimodal_inference(self, json_id, caption, image_paths):
        """å¤šæ¨¡æ€æ¨ç†ï¼ˆå›¾ç‰‡+æ–‡æœ¬ï¼‰"""
        try:
            # 1. å¤„ç†å›¾ç‰‡
            image_tensor = self.load_images(image_paths)
            
            # 2. å¤„ç†æ–‡æœ¬
            encoding = self.tokenizer(
                caption,
                truncation=True,
                padding='max_length',
                max_length=64,
                return_tensors='pt'
            )
            
            # 3. ç§»åˆ°è®¾å¤‡
            image_tensor = image_tensor.to(self.device)
            input_ids = encoding['input_ids'].to(self.device)
            attention_mask = encoding['attention_mask'].to(self.device)
            
            # 4. å¤šæ¨¡æ€æ¨ç†
            with torch.no_grad():
                output = self.model(image_tensor, input_ids, attention_mask)
                score = output.item() * 10.0  # åå½’ä¸€åŒ–åˆ°0-10
                score = max(0.0, min(10.0, score))  # é™åˆ¶èŒƒå›´
            
            return round(score, 2), len(image_paths)
            
        except Exception as e:
            logger.warning(f"å¤šæ¨¡æ€æ¨ç†å¤±è´¥ {json_id}: {e}")
            return 5.0, 0  # é»˜è®¤ä¸­æ€§åˆ†æ•°
    
    def process_brand_posts(self):
        """å¤„ç†å“ç‰Œå¸–å­è¿›è¡Œå¤šæ¨¡æ€æ¨ç†"""
        logger.info("ğŸ” è¯»å–ç­›é€‰å‡ºçš„å“ç‰Œå¸–å­...")
        
        # è¯»å–ç¬¬ä¸€é˜¶æ®µçš„ç»“æœ
        if not os.path.exists(self.brand_results_file):
            logger.error(f"âŒ å“ç‰Œç­›é€‰ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {self.brand_results_file}")
            return
        
        brand_df = pd.read_csv(self.brand_results_file)
        logger.info(f"âœ… è¯»å–åˆ° {len(brand_df)} ä¸ªå“ç‰Œå¸–å­")
        
        # åŠ è½½è¿›åº¦
        progress = self.load_progress()
        processed_count = progress['processed']
        results = progress.get('results', [])
        
        # ä»æ–­ç‚¹å¼€å§‹å¤„ç†
        posts_to_process = brand_df.iloc[processed_count:]
        logger.info(f"ğŸ“ˆ ä»ç¬¬ {processed_count} ä¸ªå¸–å­å¼€å§‹å¤šæ¨¡æ€æ¨ç†")
        logger.info(f"ğŸ“‹ å‰©ä½™å¤„ç†: {len(posts_to_process)} ä¸ªå¸–å­")
        
        save_interval = 100  # æ¯100ä¸ªå¸–å­ä¿å­˜ä¸€æ¬¡
        batch_start_time = datetime.now()
        
        with tqdm(posts_to_process.iterrows(), 
                  desc="å¤šæ¨¡æ€æ¨ç†", 
                  total=len(posts_to_process),
                  disable=DISABLE_TQDM) as pbar:
            
            for row_idx, (_, row) in enumerate(pbar):
                try:
                    json_id = str(row['json_id'])
                    influencer_name = row['influencer_name']
                    sponsored = row['sponsored']
                    brand = row['brand']
                    
                    # 1. ä»JSONæ–‡ä»¶è·å–caption
                    json_file = os.path.join(self.json_dir, f'{json_id}.json')
                    caption = ""
                    
                    if os.path.exists(json_file):
                        try:
                            with open(json_file, 'r', encoding='utf-8') as f:
                                post_data = json.load(f)
                            
                            caption_edges = post_data.get('edge_media_to_caption', {}).get('edges', [])
                            if caption_edges:
                                caption = caption_edges[0].get('node', {}).get('text', '')
                        except Exception as e:
                            logger.warning(f"è¯»å–JSONå¤±è´¥ {json_id}: {e}")
                    
                    # 2. ä»post_info.txtè·å–å›¾ç‰‡ID
                    json_filename = f'{json_id}.json'
                    image_ids = self.json_to_images.get(json_filename, [])
                    
                    # 3. æŸ¥æ‰¾å®é™…å›¾ç‰‡è·¯å¾„
                    image_paths = self.find_image_paths(image_ids)
                    
                    # 4. å¤šæ¨¡æ€æ¨ç†
                    gender_score, image_count = self.multimodal_inference(json_id, caption, image_paths)
                    
                    # 5. ä¿å­˜ç»“æœ
                    result = {
                        'json_id': json_id,
                        'influencer_name': influencer_name,
                        'sponsored': sponsored,
                        'brand': brand,
                        'gender_bias_score': gender_score,
                        'image_count': image_count,
                        'caption_length': len(caption) if caption else 0
                    }
                    
                    results.append(result)
                    processed_count += 1
                    
                    # æ›´æ–°è¿›åº¦æ¡
                    if not DISABLE_TQDM:
                        pbar.set_postfix({
                            'Brand': brand[:8],
                            'Score': f"{gender_score:.1f}",
                            'Images': image_count,
                            'Sponsored': 'Y' if sponsored else 'N'
                        })
                    
                    # åå°æ¨¡å¼çš„è¿›åº¦æ—¥å¿—
                    if DISABLE_TQDM and (row_idx + 1) % 50 == 0:
                        logger.info(f"  å·²å¤„ç† {processed_count}/{len(brand_df)} ä¸ªå¸–å­ "
                                  f"({processed_count/len(brand_df)*100:.1f}%) - "
                                  f"æœ€æ–°: {brand} {gender_score:.1f}åˆ†")
                    
                    # å®šæœŸä¿å­˜
                    if len(results) % save_interval == 0:
                        # ä¿å­˜è¿›åº¦
                        progress_data = {
                            'processed': processed_count,
                            'results': results
                        }
                        self.save_progress(progress_data)
                        
                        # ä¿å­˜CSV
                        self.save_results(results)
                        
                        # æ˜¾ç¤ºæ‰¹æ¬¡ç»Ÿè®¡
                        batch_time = (datetime.now() - batch_start_time).total_seconds()
                        speed = save_interval / batch_time
                        remaining = len(brand_df) - processed_count
                        eta_minutes = remaining / speed / 60
                        
                        logger.info(f"ğŸ’¾ å·²ä¿å­˜ {processed_count} ä¸ªç»“æœ")
                        logger.info(f"âš¡ å¤„ç†é€Ÿåº¦: {speed:.1f} å¸–å­/ç§’")
                        logger.info(f"â° é¢„è®¡å‰©ä½™: {eta_minutes:.1f} åˆ†é’Ÿ")
                        
                        batch_start_time = datetime.now()
                        
                except Exception as e:
                    logger.error(f"å¤„ç†å¸–å­å¤±è´¥ {row.get('json_id', 'unknown')}: {e}")
                    processed_count += 1
                    continue
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        progress_data = {
            'processed': processed_count,
            'results': results
        }
        self.save_progress(progress_data)
        self.save_results(results)
        
        logger.info(f"ğŸ‰ å¤šæ¨¡æ€æ¨ç†å®Œæˆï¼å¤„ç†äº† {len(results)} ä¸ªå¸–å­")
        return results
    
    def save_results(self, results):
        """ä¿å­˜ç»“æœåˆ°CSV"""
        if not results:
            return
        
        df = pd.DataFrame(results)
        df.to_csv(self.final_results_file, index=False)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        total = len(df)
        success_with_images = (df['image_count'] > 0).sum()
        avg_score = df['gender_bias_score'].mean()
        
        logger.info(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {self.final_results_file}")
        logger.info(f"ğŸ“Š æœ‰å›¾ç‰‡çš„å¸–å­: {success_with_images}/{total} ({success_with_images/total*100:.1f}%)")
        logger.info(f"ğŸ“Š å¹³å‡æ€§åˆ«å€¾å‘åˆ†æ•°: {avg_score:.2f}")
    
    def show_final_statistics(self, results):
        """æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        df = pd.DataFrame(results)
        
        logger.info("ğŸ“Š å¤šæ¨¡æ€æ¨ç†æœ€ç»ˆç»Ÿè®¡:")
        logger.info("=" * 60)
        logger.info(f"æ€»å¸–å­æ•°: {len(df):,}")
        logger.info(f"æ¶‰åŠå“ç‰Œ: {df['brand'].nunique()} ä¸ª")
        logger.info(f"æ¶‰åŠåšä¸»: {df['influencer_name'].nunique():,} ä¸ª")
        logger.info(f"èµåŠ©å¸–å­: {df['sponsored'].sum():,} ({df['sponsored'].mean()*100:.1f}%)")
        logger.info(f"æœ‰å›¾ç‰‡å¸–å­: {(df['image_count'] > 0).sum():,} ({(df['image_count'] > 0).mean()*100:.1f}%)")
        logger.info(f"å¹³å‡å›¾ç‰‡æ•°: {df['image_count'].mean():.2f}")
        logger.info(f"å¹³å‡æ€§åˆ«å€¾å‘åˆ†æ•°: {df['gender_bias_score'].mean():.2f} Â± {df['gender_bias_score'].std():.2f}")
        
        logger.info(f"\nğŸ† å„å“ç‰Œå¤šæ¨¡æ€åˆ†æç»“æœ (Top 10):")
        brand_stats = df.groupby('brand').agg({
            'gender_bias_score': ['count', 'mean', 'std'],
            'sponsored': 'mean',
            'image_count': 'mean'
        }).round(3)
        
        brand_stats.columns = ['å¸–å­æ•°', 'å¹³å‡åˆ†æ•°', 'åˆ†æ•°æ ‡å‡†å·®', 'èµåŠ©ç‡', 'å¹³å‡å›¾ç‰‡æ•°']
        brand_stats = brand_stats.sort_values('å¸–å­æ•°', ascending=False)
        
        print("\n" + brand_stats.head(10).to_string())
        
        logger.info(f"\nğŸ’¾ æœ€ç»ˆç»“æœæ–‡ä»¶: {self.final_results_file}")
    
    def run_multimodal_inference(self):
        """è¿è¡Œå®Œæ•´çš„å¤šæ¨¡æ€æ¨ç†"""
        logger.info("ğŸš€ å¼€å§‹å¤šæ¨¡æ€å“ç‰Œæ¨ç†ç³»ç»Ÿ")
        
        start_time = datetime.now()
        
        try:
            # 1. åŠ è½½post_infoæ˜ å°„
            self.load_post_info_mapping()
            
            # 2. åŠ è½½æ¨ç†æ¨¡å‹
            self.load_inference_model()
            
            # 3. å¤„ç†å“ç‰Œå¸–å­
            results = self.process_brand_posts()
            
            # 4. æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
            self.show_final_statistics(results)
            
            # 5. è®¡ç®—æ€»æ—¶é—´
            total_time = datetime.now() - start_time
            logger.info(f"â±ï¸ æ€»æ¨ç†æ—¶é—´: {total_time.total_seconds()/60:.1f} åˆ†é’Ÿ")
            logger.info("ğŸ‰ å¤šæ¨¡æ€å“ç‰Œæ¨ç†å®Œæˆï¼")
            
        except Exception as e:
            logger.error(f"âŒ å¤šæ¨¡æ€æ¨ç†å¤±è´¥: {e}")
            raise

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ¯ Instagramå“ç‰Œå¤šæ¨¡æ€æ¨ç†ç³»ç»Ÿ")
    logger.info("ç›®æ ‡: å¯¹33,829ä¸ªå“ç‰Œå¸–å­è¿›è¡Œå›¾ç‰‡+æ–‡æœ¬æ¨ç†")
    logger.info("=" * 60)
    
    # è¿è¡Œå¤šæ¨¡æ€æ¨ç†
    inferencer = MultimodalBrandInference()
    inferencer.run_multimodal_inference()

if __name__ == "__main__":
    main()


