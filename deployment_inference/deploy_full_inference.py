#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é˜¶æ®µ4: å…¨é‡æ•°æ®æ¨ç†éƒ¨ç½² (ä¿®å¤ç‰ˆ)
ä½¿ç”¨è®­ç»ƒå¥½çš„5Kæ¨¡å‹å¤„ç†160ä¸‡Instagramå¸–å­
"""

import torch
import pandas as pd
import numpy as np
import json
import os
import time
import logging
from datetime import datetime
from PIL import Image
import glob
from tqdm import tqdm
import ast
import gc

# å¯¼å…¥æ¨¡å‹
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from train_fast_local import LightweightGenderBiasModel

# è®¾ç½®ç¯å¢ƒå˜é‡é¿å…å†²çª
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# é…ç½®æ—¥å¿—
def setup_logging():
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
    log_format = '%(asctime)s - %(levelname)s - %(message)s'
    logging.basicConfig(
        level=logging.INFO,
        format=log_format,
        handlers=[
            logging.FileHandler('full_inference_fixed.log'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

logger = setup_logging()

class FixedInferenceDeployer:
    def __init__(self):
        self.model_path = '/Users/huangxinyue/Multi model distillation/fast_models_5k/fast_best_model.pth'
        self.database_path = '/Users/huangxinyue/Downloads/Influencer brand database'
        self.json_dir = os.path.join(self.database_path, 'json')
        self.post_info_file = os.path.join(self.database_path, 'post_info.txt')
        self.output_dir = '/Users/huangxinyue/Multi model distillation/full_inference_results'
        self.progress_file = os.path.join(self.output_dir, 'inference_progress_fixed.json')
        
        # æ¨ç†é…ç½®
        self.batch_size = 32  # é€‚ä¸­æ‰¹æ¬¡
        self.save_interval = 1000  # æ¯1000ä¸ªæ ·æœ¬ä¿å­˜ä¸€æ¬¡
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # æ¨¡å‹å’Œæ•°æ®
        self.model = None
        self.tokenizer = None
        self.transform = None
        self.json_to_images = {}  # JSONæ–‡ä»¶å -> å›¾ç‰‡IDåˆ—è¡¨
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.output_dir, exist_ok=True)
        
    def load_model_and_tokenizer(self):
        """åŠ è½½æ¨¡å‹å’Œtokenizer"""
        logger.info("ğŸš€ åŠ è½½5Kæœ€ä½³æ¨¡å‹...")
        
        # åŠ è½½æ¨¡å‹
        self.model = LightweightGenderBiasModel()
        checkpoint = torch.load(self.model_path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.to(self.device)
        self.model.eval()
        
        # åŠ è½½tokenizer
        from transformers import DistilBertTokenizer
        self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')
        
        # å›¾åƒé¢„å¤„ç†
        from torchvision import transforms
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        logger.info("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
        
    def load_post_info_mapping(self):
        """åŠ è½½post_info.txtæ˜ å°„ï¼ˆä¿®å¤ç‰ˆï¼‰"""
        logger.info("ğŸ“š åŠ è½½post_infoæ˜ å°„ï¼ˆæ–°æ ¼å¼ï¼‰...")
        
        try:
            with open(self.post_info_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f):
                    try:
                        parts = line.strip().split('\t')  # å°è¯•tabåˆ†éš”
                        if len(parts) < 5:
                            parts = line.strip().split()  # ç©ºæ ¼åˆ†éš”
                        
                        if len(parts) >= 5:
                            # æ ¼å¼: ç´¢å¼•å· ç”¨æˆ·å ç±»å‹ JSONæ–‡ä»¶å å›¾ç‰‡IDåˆ—è¡¨
                            json_filename = parts[3]
                            image_list_str = parts[4]
                            
                            # è§£æå›¾ç‰‡IDåˆ—è¡¨
                            try:
                                # å°è¯•è§£æPythonåˆ—è¡¨æ ¼å¼
                                image_ids = ast.literal_eval(image_list_str)
                                if isinstance(image_ids, list):
                                    # å»æ‰.jpgåç¼€ï¼Œä¿ç•™ID
                                    image_ids = [img.replace('.jpg', '') for img in image_ids]
                                    self.json_to_images[json_filename] = image_ids
                            except:
                                # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•å…¶ä»–æ ¼å¼
                                continue
                                
                    except Exception as e:
                        continue
                    
                    # æ¯10ä¸‡è¡Œæ˜¾ç¤ºè¿›åº¦
                    if (line_num + 1) % 100000 == 0:
                        logger.info(f"  å·²å¤„ç† {line_num + 1:,} è¡Œï¼Œæ‰¾åˆ° {len(self.json_to_images):,} ä¸ªæ˜ å°„")
            
            logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(self.json_to_images):,} ä¸ªJSON->å›¾ç‰‡æ˜ å°„")
            
            # æ˜¾ç¤ºå‡ ä¸ªç¤ºä¾‹
            sample_items = list(self.json_to_images.items())[:3]
            for json_file, image_ids in sample_items:
                logger.info(f"  ç¤ºä¾‹: {json_file} -> {len(image_ids)} å¼ å›¾ç‰‡")
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½post_infoå¤±è´¥: {e}")
            
    def get_all_json_files(self):
        """è·å–æ‰€æœ‰JSONæ–‡ä»¶åˆ—è¡¨"""
        logger.info("ğŸ“‚ æ‰«æJSONæ–‡ä»¶...")
        
        json_files = glob.glob(os.path.join(self.json_dir, '*.json'))
        json_files.sort()  # ä¿è¯é¡ºåºä¸€è‡´
        
        logger.info(f"ğŸ“Š å‘ç° {len(json_files):,} ä¸ªJSONæ–‡ä»¶")
        return json_files
        
    def load_progress(self):
        """åŠ è½½æ¨ç†è¿›åº¦"""
        if os.path.exists(self.progress_file):
            try:
                with open(self.progress_file, 'r') as f:
                    progress = json.load(f)
                logger.info(f"ğŸ“ˆ ç»§ç»­æ¨ç†ï¼Œå·²å¤„ç† {progress.get('processed', 0):,} ä¸ªæ ·æœ¬")
                return progress
            except:
                logger.warning("âš ï¸ æ— æ³•è¯»å–è¿›åº¦æ–‡ä»¶ï¼Œä»å¤´å¼€å§‹")
                
        return {'processed': 0, 'results': []}
        
    def save_progress(self, progress):
        """ä¿å­˜æ¨ç†è¿›åº¦"""
        try:
            with open(self.progress_file, 'w') as f:
                json.dump(progress, f)
        except Exception as e:
            logger.error(f"ä¿å­˜è¿›åº¦å¤±è´¥: {e}")
            
    def process_single_post(self, json_file_path):
        """å¤„ç†å•ä¸ªå¸–å­ï¼ˆä¿®å¤ç‰ˆï¼‰"""
        try:
            # è¯»å–JSONæ–‡ä»¶
            with open(json_file_path, 'r', encoding='utf-8') as f:
                post_data = json.load(f)
            
            post_id = post_data.get('id', os.path.basename(json_file_path).replace('.json', ''))
            caption = post_data.get('edge_media_to_caption', {}).get('edges', [])
            
            # æå–æ–‡æœ¬
            if caption and len(caption) > 0:
                text = caption[0].get('node', {}).get('text', '')
            else:
                text = ''
            
            # è·å–å›¾ç‰‡IDsï¼ˆä½¿ç”¨JSONæ–‡ä»¶åæŸ¥æ‰¾ï¼‰
            json_filename = os.path.basename(json_file_path)
            image_ids = self.json_to_images.get(json_filename, [])
            
            if not image_ids:
                return {
                    'post_id': post_id,
                    'gender_bias_score': 5.0,  # ä¸­æ€§åˆ†æ•°
                    'image_count': 0,
                    'status': 'no_images'
                }
            
            # åŠ è½½å›¾ç‰‡ (æœ€å¤š3å¼ )
            images = []
            for image_id in image_ids[:3]:
                image_path = self.find_image_path(image_id)
                if image_path and os.path.exists(image_path):
                    try:
                        image = Image.open(image_path).convert('RGB')
                        image_tensor = self.transform(image)
                        images.append(image_tensor)
                    except:
                        continue
            
            if not images:
                return {
                    'post_id': post_id,
                    'gender_bias_score': 5.0,
                    'image_count': 0,
                    'status': 'image_load_failed'
                }
            
            # å‡†å¤‡è¾“å…¥
            # å›¾ç‰‡ï¼šå–ç¬¬ä¸€å¼ æˆ–æ‹¼æ¥å¤šå¼ 
            if len(images) == 1:
                image_input = images[0].unsqueeze(0)
            else:
                # å¤šå›¾ç‰‡ï¼šå–å¹³å‡
                image_input = torch.stack(images).mean(dim=0).unsqueeze(0)
            
            # æ–‡æœ¬tokenization
            encoding = self.tokenizer(
                text,
                truncation=True,
                padding='max_length',
                max_length=64,
                return_tensors='pt'
            )
            
            # ç§»åˆ°è®¾å¤‡
            image_input = image_input.to(self.device)
            input_ids = encoding['input_ids'].to(self.device)
            attention_mask = encoding['attention_mask'].to(self.device)
            
            # æ¨ç†
            with torch.no_grad():
                output = self.model(image_input, input_ids, attention_mask)
                score = output.item() * 10.0  # åå½’ä¸€åŒ–åˆ°0-10
                score = max(0.0, min(10.0, score))  # é™åˆ¶èŒƒå›´
            
            return {
                'post_id': post_id,
                'gender_bias_score': round(score, 2),
                'image_count': len(images),
                'status': 'success'
            }
            
        except Exception as e:
            logger.warning(f"å¤„ç†å¸–å­å¤±è´¥ {json_file_path}: {e}")
            return {
                'post_id': os.path.basename(json_file_path).replace('.json', ''),
                'gender_bias_score': 5.0,
                'image_count': 0,
                'status': 'error'
            }
    
    def find_image_path(self, image_id):
        """æŸ¥æ‰¾å›¾ç‰‡æ–‡ä»¶è·¯å¾„"""
        # åœ¨å„ä¸ªimg_resizedç›®å½•ä¸­æŸ¥æ‰¾
        for i in range(1, 17):
            dir_path = os.path.join(self.database_path, f'img_resized_{i}')
            image_path = os.path.join(dir_path, f'{image_id}.jpg')
            if os.path.exists(image_path):
                return image_path
        return None
        
    def run_batch_inference(self, json_files, start_idx=0):
        """è¿è¡Œæ‰¹é‡æ¨ç†"""
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡æ¨ç†ï¼ˆä¿®å¤ç‰ˆï¼‰ï¼Œä»ç¬¬ {start_idx:,} ä¸ªæ–‡ä»¶å¼€å§‹")
        
        # åŠ è½½è¿›åº¦
        progress = self.load_progress()
        processed_count = progress['processed']
        results = progress['results']
        
        # ä»æŒ‡å®šä½ç½®å¼€å§‹
        remaining_files = json_files[start_idx:]
        total_files = len(json_files)
        
        logger.info(f"ğŸ“Š æ€»æ–‡ä»¶æ•°: {total_files:,}")
        logger.info(f"ğŸ“ˆ å·²å¤„ç†: {processed_count:,}")
        logger.info(f"ğŸ“‹ å‰©ä½™: {len(remaining_files):,}")
        
        # åˆ›å»ºè¿›åº¦æ¡
        pbar = tqdm(remaining_files, desc="ä¿®å¤æ¨ç†", initial=processed_count, total=total_files)
        
        batch_results = []
        batch_start_time = time.time()
        success_count = 0
        
        for file_idx, json_file in enumerate(remaining_files):
            result = self.process_single_post(json_file)
            batch_results.append(result)
            processed_count += 1
            
            if result['status'] == 'success':
                success_count += 1
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.update(1)
            pbar.set_postfix({
                'Score': f"{result['gender_bias_score']:.1f}",
                'Images': result['image_count'],
                'Success': f"{success_count}/{len(batch_results)}"
            })
            
            # å®šæœŸä¿å­˜
            if len(batch_results) >= self.save_interval:
                results.extend(batch_results)
                
                # ä¿å­˜è¿›åº¦
                progress = {
                    'processed': processed_count,
                    'results': results
                }
                self.save_progress(progress)
                
                # ä¿å­˜CSV
                self.save_batch_results(results)
                
                # æ¸…ç†å†…å­˜
                batch_results = []
                gc.collect()
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                batch_time = time.time() - batch_start_time
                speed = self.save_interval / batch_time
                remaining = total_files - processed_count
                eta_hours = remaining / speed / 3600
                
                logger.info(f"ğŸ’¾ å·²ä¿å­˜ {processed_count:,} ä¸ªç»“æœ")
                logger.info(f"âš¡ å¤„ç†é€Ÿåº¦: {speed:.1f} å¸–å­/ç§’")
                logger.info(f"âœ… æˆåŠŸç‡: {success_count}/{self.save_interval} ({success_count/self.save_interval*100:.1f}%)")
                logger.info(f"â° é¢„è®¡å‰©ä½™æ—¶é—´: {eta_hours:.1f} å°æ—¶")
                
                batch_start_time = time.time()
                success_count = 0
        
        # ä¿å­˜æœ€åä¸€æ‰¹
        if batch_results:
            results.extend(batch_results)
            progress = {
                'processed': processed_count,
                'results': results
            }
            self.save_progress(progress)
            self.save_batch_results(results)
        
        pbar.close()
        logger.info("ğŸ‰ æ‰¹é‡æ¨ç†å®Œæˆï¼")
        
        return results
        
    def save_batch_results(self, results):
        """ä¿å­˜æ‰¹æ¬¡ç»“æœåˆ°CSV"""
        if not results:
            return
            
        df = pd.DataFrame(results)
        output_file = os.path.join(self.output_dir, 'full_inference_results_fixed.csv')
        
        df.to_csv(output_file, index=False)
        logger.info(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {output_file}")
        
        # æ˜¾ç¤ºå¿«é€Ÿç»Ÿè®¡
        success_count = (df['status'] == 'success').sum()
        if success_count > 0:
            avg_score = df[df['status'] == 'success']['gender_bias_score'].mean()
            logger.info(f"ğŸ“Š æˆåŠŸå¤„ç†: {success_count:,} / {len(df):,} ({success_count/len(df)*100:.1f}%)")
            logger.info(f"ğŸ“Š å¹³å‡åˆ†æ•°: {avg_score:.2f}")
        
    def deploy(self):
        """ä¸»éƒ¨ç½²å‡½æ•°"""
        logger.info("ğŸš€ å¼€å§‹é˜¶æ®µ4: å…¨é‡æ•°æ®æ¨ç†éƒ¨ç½²ï¼ˆä¿®å¤ç‰ˆï¼‰")
        
        start_time = time.time()
        
        # 1. åŠ è½½æ¨¡å‹
        self.load_model_and_tokenizer()
        
        # 2. åŠ è½½æ•°æ®æ˜ å°„ï¼ˆä¿®å¤ç‰ˆï¼‰
        self.load_post_info_mapping()
        
        # 3. è·å–æ‰€æœ‰JSONæ–‡ä»¶
        json_files = self.get_all_json_files()
        
        # 4. æ£€æŸ¥è¿›åº¦
        progress = self.load_progress()
        start_idx = progress['processed']
        
        # 5. è¿è¡Œæ¨ç†
        results = self.run_batch_inference(json_files, start_idx)
        
        # 6. æœ€ç»ˆç»Ÿè®¡
        total_time = time.time() - start_time
        total_hours = total_time / 3600
        
        logger.info("ğŸ‰ å…¨é‡æ¨ç†éƒ¨ç½²å®Œæˆï¼")
        logger.info(f"â±ï¸ æ€»è€—æ—¶: {total_hours:.2f} å°æ—¶")
        logger.info(f"ğŸ“Š å¤„ç†æ ·æœ¬: {len(results):,}")
        logger.info(f"ğŸ“ ç»“æœæ–‡ä»¶: {self.output_dir}/full_inference_results_fixed.csv")

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ¯ Instagramæ€§åˆ«å€¾å‘é¢„æµ‹ - å…¨é‡éƒ¨ç½²ï¼ˆä¿®å¤ç‰ˆï¼‰")
    
    deployer = FixedInferenceDeployer()
    deployer.deploy()

if __name__ == "__main__":
    main()





