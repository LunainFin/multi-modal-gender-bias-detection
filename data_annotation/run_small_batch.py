#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°æ‰¹é‡æµ‹è¯•ç¨‹åº - ä½¿ç”¨å½“å‰ç›®å½•çš„æ ·æœ¬æ•°æ®éªŒè¯å®Œæ•´æµç¨‹
"""

import json
import os
import requests
import base64
import time
from typing import List, Dict, Optional
import csv
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SmallBatchProcessor:
    def __init__(self):
        """
        ä½¿ç”¨å½“å‰ç›®å½•çš„æ ·æœ¬æ•°æ®è¿›è¡Œæ‰¹é‡å¤„ç†æµ‹è¯•ï¼ˆæ‰€æœ‰å¯ç”¨æ ·æœ¬ï¼‰
        """
        self.current_dir = "/Users/huangxinyue/Multi model distillation"
        self.api_key = "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"
        self.model_name = "qwen/qwen2.5-vl-32b-instruct:free"
        self.results = []
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = os.path.join(self.current_dir, "batch_all_results")
        os.makedirs(self.output_dir, exist_ok=True)
    
    def load_sample_data(self) -> List[Dict]:
        """
        åŠ è½½å½“å‰ç›®å½•çš„æ ·æœ¬æ•°æ®
        """
        logger.info("åŠ è½½æ ·æœ¬æ•°æ®...")
        
        json_dir = os.path.join(self.current_dir, "json_samples")
        json_files = [f for f in os.listdir(json_dir) if f.endswith('.json')]  # å¤„ç†æ‰€æœ‰å¯ç”¨æ ·æœ¬
        
        samples = []
        for json_file in json_files:
            try:
                json_path = os.path.join(json_dir, json_file)
                with open(json_path, 'r', encoding='utf-8') as f:
                    post_data = json.load(f)
                
                # æå–caption
                caption = ""
                if 'edge_media_to_caption' in post_data and post_data['edge_media_to_caption']['edges']:
                    caption = post_data['edge_media_to_caption']['edges'][0]['node']['text']
                
                post_id = post_data.get('id', json_file.replace('.json', ''))
                
                samples.append({
                    'post_id': post_id,
                    'caption': caption,
                    'json_file': json_file
                })
                
            except Exception as e:
                logger.warning(f"åŠ è½½{json_file}å¤±è´¥: {e}")
        
        logger.info(f"æˆåŠŸåŠ è½½{len(samples)}ä¸ªæ ·æœ¬")
        return samples
    
    def call_qwen_api(self, caption: str) -> Optional[dict]:
        """
        è°ƒç”¨Qwen APIè¿›è¡Œæ€§åˆ«åè§è¯„åˆ†ï¼ˆçº¯æ–‡æœ¬ç‰ˆæœ¬ï¼‰
        """
        try:
            # æ„å»ºAPIè¯·æ±‚
            content = [
                {
                    "type": "text",
                    "text": f"è¯·æ ¹æ®ä»¥ä¸‹Instagramå¸–å­çš„å†…å®¹åˆ¤æ–­å…¶æ€§åˆ«å€¾å‘ç¨‹åº¦ï¼Œæ€§åˆ«å€¾å‘è¶Šå¼ºåˆ†æ•°è¶Šé«˜ã€‚\n\nè¦æ±‚ï¼š\n1. å…ˆç»™å‡º0åˆ°10ä¹‹é—´çš„æ•°å­—åˆ†æ•°\n2. ç„¶åç”¨ä¸€å¥è¯è§£é‡Šæ‰“åˆ†åŸå› \n3. æ ¼å¼ï¼šåˆ†æ•°: X.X | åŸå› : [è§£é‡Š]\n\nå¸–å­å†…å®¹ï¼š{caption}"
                }
            ]
            
            payload = {
                "model": self.model_name,
                "messages": [
                    {
                        "role": "user",
                        "content": content
                    }
                ],
                "max_tokens": 100,  # å¢åŠ tokenæ•°é‡ä»¥å®¹çº³è§£é‡Š
                "temperature": 0.1
            }
            
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://github.com/multi-model-distillation",
                "X-Title": "Multi-Model Gender Bias Analysis"
            }
            
            # å‘é€APIè¯·æ±‚
            response = requests.post(
                url="https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content'].strip()
                
                # è§£æåˆ†æ•°å’Œè§£é‡Š
                try:
                    # å°è¯•æŒ‰æ ¼å¼è§£æ: "åˆ†æ•°: X.X | åŸå› : [è§£é‡Š]"
                    if '|' in content:
                        parts = content.split('|')
                        score_part = parts[0].strip()
                        reason_part = parts[1].strip() if len(parts) > 1 else ""
                        
                        # æå–åˆ†æ•°
                        import re
                        score_match = re.search(r'(\d+(?:\.\d+)?)', score_part)
                        if score_match:
                            score = float(score_match.group(1))
                            if 0 <= score <= 10:
                                # æå–è§£é‡Š
                                reason = reason_part.replace('åŸå› :', '').replace('åŸå› ï¼š', '').strip()
                                return {
                                    'score': score,
                                    'reason': reason,
                                    'raw_response': content
                                }
                        
                    # å¤‡ç”¨è§£ææ–¹å¼ï¼šå¦‚æœæ ¼å¼ä¸æ ‡å‡†ï¼Œå°è¯•æå–æ•°å­—
                    numbers = re.findall(r'\d+(?:\.\d+)?', content)
                    if numbers:
                        score = float(numbers[0])
                        if 0 <= score <= 10:
                            return {
                                'score': score,
                                'reason': content,  # æ•´ä¸ªå›å¤ä½œä¸ºè§£é‡Š
                                'raw_response': content
                            }
                    
                    logger.warning(f"æ— æ³•è§£æè¿”å›çš„åˆ†æ•°å’Œè§£é‡Š: {content}")
                    return None
                    
                except Exception as e:
                    logger.warning(f"è§£æå“åº”æ—¶å‡ºé”™: {e}, åŸå§‹å†…å®¹: {content}")
                    return None
            else:
                logger.error(f"APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            logger.error(f"APIè°ƒç”¨å¼‚å¸¸: {e}")
            return None
    
    def process_samples(self, samples: List[Dict]) -> None:
        """
        å¤„ç†æ ·æœ¬å¹¶ä¿å­˜ç»“æœ
        """
        logger.info(f"å¼€å§‹å¤„ç†{len(samples)}ä¸ªæ ·æœ¬...")
        
        for i, sample in enumerate(samples):
            if (i + 1) % 5 == 0 or i == 0 or i == len(samples) - 1:
                logger.info(f"å¤„ç†ç¬¬{i+1}/{len(samples)}ä¸ªæ ·æœ¬: {sample['post_id']}")
            
            try:
                # è°ƒç”¨APIè·å–åˆ†æ•°å’Œè§£é‡Š
                api_result = self.call_qwen_api(sample['caption'])
                
                # ä¿å­˜ç»“æœ
                result = {
                    'post_id': sample['post_id'],
                    'caption': sample['caption'][:200] + "..." if len(sample['caption']) > 200 else sample['caption'],
                    'gender_bias_score': api_result['score'] if api_result else None,
                    'explanation': api_result['reason'] if api_result else None,
                    'raw_response': api_result['raw_response'] if api_result else None,
                    'json_file': sample['json_file']
                }
                
                self.results.append(result)
                
                if api_result is not None:
                    logger.info(f"âœ… è·å¾—åˆ†æ•°: {api_result['score']}")
                    logger.info(f"ğŸ’­ è§£é‡Š: {api_result['reason']}")
                else:
                    logger.warning(f"âš ï¸ åˆ†æ•°è·å–å¤±è´¥")
                
                # æ¯5ä¸ªæ ·æœ¬æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦ç»Ÿè®¡
                if (i + 1) % 5 == 0 or i == len(samples) - 1:
                    success_count = len([r for r in self.results if r['gender_bias_score'] is not None])
                    logger.info(f"ğŸ“Š å·²å¤„ç†{i+1}ä¸ªï¼ŒæˆåŠŸ{success_count}ä¸ªï¼ŒæˆåŠŸç‡{success_count/(i+1)*100:.1f}%")
                
                # APIé™æµæ§åˆ¶
                time.sleep(1.5)  # æ¯æ¬¡è¯·æ±‚é—´éš”1.5ç§’
                
            except Exception as e:
                logger.error(f"å¤„ç†æ ·æœ¬æ—¶å‡ºé”™ (PostID: {sample['post_id']}): {e}")
    
    def save_results(self) -> None:
        """
        ä¿å­˜å¤„ç†ç»“æœ
        """
        if not self.results:
            logger.warning("æ²¡æœ‰ç»“æœæ•°æ®å¯ä¿å­˜")
            return
        
        # ä¿å­˜CSVæ–‡ä»¶
        csv_path = os.path.join(self.output_dir, "batch_all_results.csv")
        try:
            with open(csv_path, 'w', newline='', encoding='utf-8') as f:
                fieldnames = self.results[0].keys()
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(self.results)
            
            logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {csv_path}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜CSVç»“æœæ—¶å‡ºé”™: {e}")
        
        # ä¿å­˜JSONæ–‡ä»¶
        json_path = os.path.join(self.output_dir, "batch_all_results.json")
        try:
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(self.results, f, indent=2, ensure_ascii=False)
            
            logger.info(f"JSONç»“æœå·²ä¿å­˜åˆ°: {json_path}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜JSONç»“æœæ—¶å‡ºé”™: {e}")
    
    def generate_summary(self) -> None:
        """
        ç”Ÿæˆç»“æœæ‘˜è¦
        """
        if not self.results:
            logger.warning("æ²¡æœ‰ç»“æœæ•°æ®ï¼Œæ— æ³•ç”Ÿæˆæ‘˜è¦")
            return
        
        valid_scores = [r['gender_bias_score'] for r in self.results if r['gender_bias_score'] is not None]
        
        if valid_scores:
            summary = {
                'total_samples': len(self.results),
                'valid_scores_count': len(valid_scores),
                'success_rate': len(valid_scores) / len(self.results) * 100,
                'mean_score': sum(valid_scores) / len(valid_scores),
                'min_score': min(valid_scores),
                'max_score': max(valid_scores),
                'scores': valid_scores
            }
            
            logger.info("=== å¤„ç†ç»“æœæ‘˜è¦ ===")
            logger.info(f"æ€»æ ·æœ¬æ•°: {summary['total_samples']}")
            logger.info(f"æˆåŠŸè·å¾—åˆ†æ•°: {summary['valid_scores_count']}")
            logger.info(f"æˆåŠŸç‡: {summary['success_rate']:.1f}%")
            logger.info(f"å¹³å‡åˆ†æ•°: {summary['mean_score']:.2f}")
            logger.info(f"åˆ†æ•°èŒƒå›´: {summary['min_score']:.1f} - {summary['max_score']:.1f}")
            logger.info(f"æ‰€æœ‰åˆ†æ•°: {summary['scores']}")
            
            # ä¿å­˜æ‘˜è¦
            summary_path = os.path.join(self.output_dir, "summary.json")
            with open(summary_path, 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)
            
            logger.info(f"æ‘˜è¦å·²ä¿å­˜åˆ°: {summary_path}")
        else:
            logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„åˆ†æ•°æ•°æ®")
    
    def run(self) -> None:
        """
        è¿è¡Œå°æ‰¹é‡å¤„ç†æµç¨‹
        """
        logger.info("ğŸš€ å¼€å§‹å¤„ç†æ‰€æœ‰å¯ç”¨æ ·æœ¬...")
        
        # 1. åŠ è½½æ ·æœ¬æ•°æ®
        samples = self.load_sample_data()
        if not samples:
            logger.error("âŒ æ ·æœ¬åŠ è½½å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
            return
        
        # 2. å¤„ç†æ ·æœ¬
        self.process_samples(samples)
        
        # 3. ä¿å­˜ç»“æœ
        self.save_results()
        
        # 4. ç”Ÿæˆæ‘˜è¦
        self.generate_summary()
        
        logger.info("âœ… æ‰€æœ‰æ ·æœ¬æ‰¹é‡å¤„ç†å®Œæˆï¼")
        logger.info("ğŸ’¡ å¦‚æœç»“æœæ»¡æ„ï¼Œå¯ä»¥è¿è¡Œå®Œæ•´çš„extract_and_score_samples.pyå¤„ç†50Kæ ·æœ¬")


def main():
    """
    ä¸»ç¨‹åºå…¥å£
    """
    processor = SmallBatchProcessor()
    processor.run()


if __name__ == "__main__":
    main()
